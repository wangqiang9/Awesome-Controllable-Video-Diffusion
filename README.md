# Awesome-Controllable-Video-Diffusion
[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/hee9joon/Awesome-Diffusion-Models) 
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](https://opensource.org/licenses/MIT)

Awesome Controllable Video Generation with Diffusion Models.

## Pose Control
Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free Videos

[ğŸ“„ Paper](https://arxiv.org/abs/2304.01186) | [ğŸŒ Project Page](https://follow-your-pose.github.io/) [ğŸ’» Code](https://github.com/mayuelala/FollowYourPose)

Animate Anyone: Consistent and Controllable Image-to-Video Synthesis for Character Animation

[ğŸ“„ Paper](https://arxiv.org/pdf/2311.17117.pdf) | [ğŸŒ Project Page](https://humanaigc.github.io/animate-anyone/)

DreaMoving: A Human Video Generation Framework based on Diffusion Models

[ğŸ“„ Paper](https://arxiv.org/abs/2312.05107) | [ğŸŒ Project Page](https://dreamoving.github.io/dreamoving/) [ğŸ’» Code](https://github.com/dreamoving/dreamoving-project)

MagicPose: Realistic Human Poses and Facial Expressions Retargeting with Identity-aware Diffusion

[ğŸ“„ Paper](https://arxiv.org/abs/2311.12052) | [ğŸŒ Project Page](https://boese0601.github.io/magicdance/) [ğŸ’» Code](https://github.com/Boese0601/MagicDance)

MagicAnimate: Temporally Consistent Human Image Animation using Diffusion Model

[ğŸ“„ Paper](https://arxiv.org/abs/2406.01188) | [ğŸŒ Project Page](https://showlab.github.io/magicanimate/) [ğŸ’» Code](https://github.com/magic-research/magic-animate)

Champ: Controllable and Consistent Human Image Animation with 3D Parametric Guidance

[ğŸ“„ Paper](https://arxiv.org/pdf/2403.14781) | [ğŸŒ Project Page](https://fudan-generative-vision.github.io/champ/#/) [ğŸ’» Code](https://github.com/fudan-generative-vision/champ)

Magic-Me: Identity-Specific Video Customized Diffusion

[ğŸ“„ Paper](https://arxiv.org/abs/2402.09368) | [ğŸŒ Project Page](https://magic-me-webpage.github.io/) [ğŸ’» Code](https://github.com/Zhen-Dong/Magic-Me)

DisCo: Disentangled Control for Referring Human Dance Generation in Real World

[ğŸ“„ Paper](https://arxiv.org/abs/2307.00040) | [ğŸŒ Project Page](https://disco-dance.github.io/) [ğŸ’» Code](https://github.com/Wangt-CN/DisCo)

Human4DiT: Free-view Human Video Generation with 4D Diffusion Transformer

[ğŸ“„ Paper](https://arxiv.org/abs/2405.17405) | [ğŸŒ Project Page](https://human4dit.github.io/)

MimicMotion : High-Quality Human Motion Video Generation with Confidence-aware Pose Guidance

[ğŸ“„ Paper](https://arxiv.org/abs/2406.19680) | [ğŸŒ Project Page](https://tencent.github.io/MimicMotion/) [ğŸ’» Code](https://github.com/tencent/MimicMotion)

Follow-Your-Pose v2: Multiple-Condition Guided Character Image Animation for Stable Pose Control

[ğŸ“„ Paper](https://arxiv.org/abs/2406.03035) | [ğŸŒ Project Page](https://follow-your-pose-v2.github.io/)

HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation

[ğŸ“„ Paper](https://arxiv.org/abs/2407.17438) | [ğŸŒ Project Page](https://humanvid.github.io/) [ğŸ’» Code](https://github.com/zhenzhiwang/HumanVid)

Follow Your Pose: Pose-Guided Text-to-Video Generation using Pose-Free Videos

[ğŸ“„ Paper](https://arxiv.org/abs/2304.01186) | [ğŸŒ Project Page](https://follow-your-pose.github.io/) [ğŸ’» Code](https://github.com/mayuelala/FollowYourPose)

## Motion Control




## Camera Control
MotionCtrl: A Unified and Flexible Motion Controller for Video Generation

[ğŸ“„ Paper](https://arxiv.org/pdf/2312.03641.pdf) | [ğŸŒ Project Page](https://wzhouxiff.github.io/projects/MotionCtrl/) [ğŸ’» Code](https://github.com/TencentARC/MotionCtrl)

CameraCtrl: Enabling Camera Control for Text-to-Video Generation

[ğŸ“„ Paper](https://arxiv.org/abs/2404.02101) | [ğŸŒ Project Page](https://hehao13.github.io/projects-CameraCtrl/) [ğŸ’» Code](https://github.com/hehao13/CameraCtrl)

VD3D: Taming Large Video Diffusion Transformers for 3D Camera Control

[ğŸ“„ Paper](https://arxiv.org/abs/2407.12781) | [ğŸŒ Project Page](https://snap-research.github.io/vd3d/)

Controlling Space and Time with Diffusion Models

[ğŸ“„ Paper](https://arxiv.org/pdf/2407.07860) | [ğŸŒ Project Page](https://4d-diffusion.github.io/)

CamCo: Camera-Controllable 3D-Consistent Image-to-Video Generation

[ğŸ“„ Paper](https://arxiv.org/abs/2406.02509) | [ğŸŒ Project Page](https://ir1d.github.io/CamCo/)

Collaborative Video Diffusion: Consistent Multi-video Generation with Camera Control

[ğŸ“„ Paper](https://arxiv.org/pdf/2405.17414) | [ğŸŒ Project Page](https://collaborativevideodiffusion.github.io/)

HumanVid: Demystifying Training Data for Camera-controllable Human Image Animation

[ğŸ“„ Paper](https://arxiv.org/abs/2407.17438) | [ğŸŒ Project Page](https://humanvid.github.io/) [ğŸ’» Code](https://github.com/zhenzhiwang/HumanVid)
